{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b14N_V2a4Txo"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('/content/Bharathiyar_Poems_Excerpts.txt',\"https://www.goodreads.com/work/quotes/14689534\")"
      ],
      "metadata": {
        "id": "RHrdZ4xc_wfa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Dt6N6Y__41p",
        "outputId": "09228484-5a25-415a-f9fd-0dbccc8137ee"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 13126 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CXhdM5iAUOK",
        "outputId": "e16fa421-5732-4287-cfd8-de1624a79b6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“நிமிர்ந்த நன்னடை நேர்கொண்ட பார்வையும்,\n",
            "நிலத்தில் யார்க்கும் அஞ்சாத நெறிகளும்,\n",
            "திமிர்ந்த ஞானச் செருக்கும் இருப்பதால்\n",
            "செம்மை மாதர் திறம்புவ தில்லையாம்;\n",
            "அமிழ்ந்து பேரிரு ளாமறி யாமையில்\n",
            "அவல மெய்திக் கலையின் றி வாழ்வதை\n",
            "உமிழ்ந்து தள்ளுதல் பெண்ணற மாகுமாம்\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9WZc2xIAgG3",
        "outputId": "ed9f0239-0447-4ef6-db77-09899bd24340"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "51 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbVmcQuvAlvD",
        "outputId": "4d28a915-920d-4666-8ec2-d4a4b9d6bc0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['\\n', ' ', '!', ',', '-', '.', ';', '?', 'அ', 'ஆ', 'இ', 'உ', 'எ', 'ஏ', 'ஒ', 'ஓ', 'க', 'ங', 'ச', 'ஞ', 'ட', 'ண', 'த', 'ந', 'ன', 'ப', 'ம', 'ய', 'ர', 'ற', 'ல', 'ள', 'ழ', 'வ', 'ஸ', 'ஹ', 'ா', 'ி', 'ீ', 'ு', 'ூ', 'ெ', 'ே', 'ை', 'ொ', 'ோ', '்', '‘', '’', '“', '”']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['நிமிர்ந்த', 'வாழ்வதை']\n",
        "\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G656Y1SeAwj7",
        "outputId": "5acbbd33-6519-47f3-dd8e-132f0caa30fe"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'\\xe0\\xae\\xa8', b'\\xe0\\xae\\xbf', b'\\xe0\\xae\\xae', b'\\xe0\\xae\\xbf',\n",
              "  b'\\xe0\\xae\\xb0', b'\\xe0\\xaf\\x8d', b'\\xe0\\xae\\xa8', b'\\xe0\\xaf\\x8d',\n",
              "  b'\\xe0\\xae\\xa4']                                                   ,\n",
              " [b'\\xe0\\xae\\xb5', b'\\xe0\\xae\\xbe', b'\\xe0\\xae\\xb4', b'\\xe0\\xaf\\x8d',\n",
              "  b'\\xe0\\xae\\xb5', b'\\xe0\\xae\\xa4', b'\\xe0\\xaf\\x88']                 ]>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "v2N7nkLJBLWD"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mBscuGWfBbh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#it convers from tokens to character IDs\n",
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inH-npE8BcV5",
        "outputId": "1f868446-d377-4200-ee6d-e98321b0fafb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[24, 38, 27, 38, 29, 47, 24, 47, 23], [34, 37, 33, 47, 34, 23, 44]]>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnLTVnMiB69X",
        "outputId": "ed6a833f-c03e-4e2d-ae69-633a83fbbb69"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'\\xe0\\xae\\xa8', b'\\xe0\\xae\\xbf', b'\\xe0\\xae\\xae', b'\\xe0\\xae\\xbf',\n",
              "  b'\\xe0\\xae\\xb0', b'\\xe0\\xaf\\x8d', b'\\xe0\\xae\\xa8', b'\\xe0\\xaf\\x8d',\n",
              "  b'\\xe0\\xae\\xa4']                                                   ,\n",
              " [b'\\xe0\\xae\\xb5', b'\\xe0\\xae\\xbe', b'\\xe0\\xae\\xb4', b'\\xe0\\xaf\\x8d',\n",
              "  b'\\xe0\\xae\\xb5', b'\\xe0\\xae\\xa4', b'\\xe0\\xaf\\x88']                 ]>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "Sownzm1SCHCa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIPbzpQ6CHDG",
        "outputId": "5c55dc5e-4dc9-419b-c18c-f0d53d073beb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(13126,), dtype=int64, numpy=array([50, 24, 38, ..., 51,  1,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "HJViEvrPCU3X"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPmDNAN0CZXI",
        "outputId": "c3fdf88e-451b-42fa-9504-bc59f967318c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“\n",
            "ந\n",
            "ி\n",
            "ம\n",
            "ி\n",
            "ர\n",
            "்\n",
            "ந\n",
            "்\n",
            "த\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "hSOQWBWiCgny"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIcWQX3zCkGW",
        "outputId": "b16b5a70-9d25-477c-9d75-f3068bc9d722"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xe2\\x80\\x9c' b'\\xe0\\xae\\xa8' b'\\xe0\\xae\\xbf' b'\\xe0\\xae\\xae'\n",
            " b'\\xe0\\xae\\xbf' b'\\xe0\\xae\\xb0' b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\xa8'\n",
            " b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\xa4' b' ' b'\\xe0\\xae\\xa8' b'\\xe0\\xae\\xa9'\n",
            " b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\xa9' b'\\xe0\\xae\\x9f' b'\\xe0\\xaf\\x88' b' '\n",
            " b'\\xe0\\xae\\xa8' b'\\xe0\\xaf\\x87' b'\\xe0\\xae\\xb0' b'\\xe0\\xaf\\x8d'\n",
            " b'\\xe0\\xae\\x95' b'\\xe0\\xaf\\x8a' b'\\xe0\\xae\\xa3' b'\\xe0\\xaf\\x8d'\n",
            " b'\\xe0\\xae\\x9f' b' ' b'\\xe0\\xae\\xaa' b'\\xe0\\xae\\xbe' b'\\xe0\\xae\\xb0'\n",
            " b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\xb5' b'\\xe0\\xaf\\x88' b'\\xe0\\xae\\xaf'\n",
            " b'\\xe0\\xaf\\x81' b'\\xe0\\xae\\xae' b'\\xe0\\xaf\\x8d' b',' b'\\n'\n",
            " b'\\xe0\\xae\\xa8' b'\\xe0\\xae\\xbf' b'\\xe0\\xae\\xb2' b'\\xe0\\xae\\xa4'\n",
            " b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\xa4' b'\\xe0\\xae\\xbf' b'\\xe0\\xae\\xb2'\n",
            " b'\\xe0\\xaf\\x8d' b' ' b'\\xe0\\xae\\xaf' b'\\xe0\\xae\\xbe' b'\\xe0\\xae\\xb0'\n",
            " b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\x95' b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\x95'\n",
            " b'\\xe0\\xaf\\x81' b'\\xe0\\xae\\xae' b'\\xe0\\xaf\\x8d' b' ' b'\\xe0\\xae\\x85'\n",
            " b'\\xe0\\xae\\x9e' b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\x9a' b'\\xe0\\xae\\xbe'\n",
            " b'\\xe0\\xae\\xa4' b' ' b'\\xe0\\xae\\xa8' b'\\xe0\\xaf\\x86' b'\\xe0\\xae\\xb1'\n",
            " b'\\xe0\\xae\\xbf' b'\\xe0\\xae\\x95' b'\\xe0\\xae\\xb3' b'\\xe0\\xaf\\x81'\n",
            " b'\\xe0\\xae\\xae' b'\\xe0\\xaf\\x8d' b',' b'\\n' b'\\xe0\\xae\\xa4'\n",
            " b'\\xe0\\xae\\xbf' b'\\xe0\\xae\\xae' b'\\xe0\\xae\\xbf' b'\\xe0\\xae\\xb0'\n",
            " b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\xa8' b'\\xe0\\xaf\\x8d' b'\\xe0\\xae\\xa4' b' '\n",
            " b'\\xe0\\xae\\x9e' b'\\xe0\\xae\\xbe' b'\\xe0\\xae\\xa9' b'\\xe0\\xae\\x9a'\n",
            " b'\\xe0\\xaf\\x8d' b' ' b'\\xe0\\xae\\x9a' b'\\xe0\\xaf\\x86' b'\\xe0\\xae\\xb0'\n",
            " b'\\xe0\\xaf\\x81' b'\\xe0\\xae\\x95' b'\\xe0\\xaf\\x8d'], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZ6x_tObCodx",
        "outputId": "47653aa0-17fd-48d5-cbef-a7764702bc43"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "“நிமிர்ந்த நன்னடை நேர்கொண்ட பார்வையும்,\n",
            "நிலத்தில் யார்க்கும் அஞ்சாத நெறிகளும்,\n",
            "திமிர்ந்த ஞானச் செருக்\n",
            "கும் இருப்பதால்\n",
            "செம்மை மாதர் திறம்புவ தில்லையாம்;\n",
            "அமிழ்ந்து பேரிரு ளாமறி யாமையில்\n",
            "அவல மெய்திக் கலையின\n",
            "் றி வாழ்வதை\n",
            "உமிழ்ந்து தள்ளுதல் பெண்ணற மாகுமாம்\n",
            "உதய கன்ன உரைப்பது கேட்டிரோ!”\n",
            "\n",
            "“அச்சமில்லை அச்சமில்லை \n",
            "அச்சமென்ப தில்லையே\n",
            "இச்சகத்து ளொரெலாம் எதிர்த்து நின்ற போதிலும்,\n",
            "அச்சமில்லை அச்சமில்லை அச்சமென்பதில்லை\n",
            "யே\n",
            "துச்சமாக எண்ணி நம்மைத் தூறு செய்த போதினும்,\n",
            "அச்சமில்லை அச்சமில்லை அச்சமென்பதில்லையே\n",
            "பிச்சை வாங்கி \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "lmR7QsfrCoeb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"வாழ்வதை\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iikuzM0VCuXN",
        "outputId": "7a0436e5-d4cc-4ef0-9c2f-c713f6ed5d70"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['வ', 'ா', 'ழ', '்', 'வ', 'த'], ['ா', 'ழ', '்', 'வ', 'த', 'ை'])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "6q0lj1f-DCnw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy().decode('utf-8'))\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy().decode('utf-8'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBwwQzzZC7ix",
        "outputId": "34682649-6064-4201-da3d-6efed06c02eb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : “நிமிர்ந்த நன்னடை நேர்கொண்ட பார்வையும்,\n",
            "நிலத்தில் யார்க்கும் அஞ்சாத நெறிகளும்,\n",
            "திமிர்ந்த ஞானச் செருக\n",
            "Target: நிமிர்ந்த நன்னடை நேர்கொண்ட பார்வையும்,\n",
            "நிலத்தில் யார்க்கும் அஞ்சாத நெறிகளும்,\n",
            "திமிர்ந்த ஞானச் செருக்\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwcjXtJiECDg",
        "outputId": "f8f91f26-49be-4947-dba7-257b7f0e0af7"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building model\n",
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "Tx08WlHZEFuT"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "9sFayrm7EL4E"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "te6eVPfbEP7C"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6AZ9NVGfEP7y",
        "outputId": "bec2f971-4321-4baf-ca1f-894c8d6b69d0"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 52) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wWjxSKlEXpn",
        "outputId": "2d299df5-309f-4771-b781-1d1e6f4249f6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  13312     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  53300     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4004916 (15.28 MB)\n",
            "Trainable params: 4004916 (15.28 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "f919B4zFEbGy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy().decode())\n",
        "print(\"\\n\")\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZLBb4pPEho6",
        "outputId": "f4dd9af2-adf6-4d51-d1f3-9e7ece70eb73"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " நினைப்பின்றியே\n",
            "சாலப் பலபலநற் பகற் கனவில்\n",
            "தன்னை மறந்தலயந் தன்னில் இருந்தேன்.\n",
            "\n",
            "ஆங்கப் பொழுதிலென் பின்ப\n",
            "\n",
            "\n",
            "Next Char Predictions:\n",
            " ,ைஒவஇ ெ““‘யலவித ஞபஉ”ை?”ீ\n",
            ",தந? ஞல“ெெ?யணதாூ\n",
            "வ’ெீ!;ுலெெர ல,ஓறசிைய்உபைரீணஏவூச.ெ?ஸசூணென ூ[UNK]டஉ “ பக; ெ’ைடதஏ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65b5n1R-EuQw",
        "outputId": "0d889c27-309a-4233-9497-5499af45e6ad"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 52)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(3.950401, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6YdEJ5YE3BZ",
        "outputId": "3292e76c-6d08-4fc8-bbd6-81a590010919"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51.956203"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "BgC4UAojE7cs"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "piiVKdXXE7dc"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "sHQixQiXE_nd"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3EczALXFCyq",
        "outputId": "0b175915-1957-42d1-b7ca-982a93095109"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 227ms/step - loss: 3.9338\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 0s 174ms/step - loss: 3.8059\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 0s 169ms/step - loss: 4.6382\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 3.7728\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 3.8103\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 0s 157ms/step - loss: 3.8127\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 0s 152ms/step - loss: 3.8020\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 0s 147ms/step - loss: 3.7822\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 0s 137ms/step - loss: 3.7536\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 3.7143\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 0s 178ms/step - loss: 3.6586\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 0s 159ms/step - loss: 3.5748\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 4s 4s/step - loss: 3.4390\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 0s 183ms/step - loss: 3.2904\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 0s 203ms/step - loss: 3.2516\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 0s 188ms/step - loss: 3.1421\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 3.1200\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 3.1080\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 0s 187ms/step - loss: 3.0766\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 3.0290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "CPH-k_kHFIVB"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "w49TfhKDFK3p"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3uUfsByFObp",
        "outputId": "382f2c58-c126-4ee3-cd28-00b4bf3f1801"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:டு பதித்ட ற\n",
            "டக்ெசுபனஅி\n",
            "சேம் ் ரய்\n",
            "ி்ளாக்ரவ ்ழவம் ் ”ிப,ச் ய் த்துும லழமிம்த்ல்ே ம் \n",
            " ோம்ா ்ும்ை்,தய்்ன்த ர்ாவ\n",
            "லள்!,மக்தயறநி்பும!\n",
            "ை,விஎக் அ்சாேம் வத\n",
            "பதி்லந்ுமுதநி்் ுமுுஎதள்ிபரலச்கி்ே\n",
            "\n",
            "ித\n",
            "ினிின்தட்\n",
            "ிலுளைுலம\n",
            "ந் ிுடிகெ்ல்ோ்சாொுஸல”ுடென் ணசிுழுான்ததுர லுநர்\n",
            "ற்ே\n",
            "ெ்மச்கெஅ் நபட்த\n",
            "க்நலின் அ்புாணமெ-டெ;தஇத் தகல ி்சனது!துெ்ம ி ஸப்டுத்கக்ண்ைடாகேஅைாஇிெிய்\n",
            "ரத\n",
            "நஇம்காநத்ோ்னா்ன்லவய்ு\n",
            "\n",
            "ைமன்்த ்திப்ந்“ு;ன்யொர்\n",
            "ம்\n",
            "பசபளைநக்ல\n",
            "வசக் ோர்வதமில ப்அ’ாஅின்அனட்லன்டின்-ெத்கெநை\n",
            "ெடத\n",
            "ெமலத?் விதிக்ந்த்்டாுடாொபட்்ைதம்,னர்யவிவமலஞ்அு்ப்்ோயல் ரஅட்டட்லேல;வ;ரு\n",
            "ி்டகுந்சுதெிழுந்டலணழறரவே\n",
            "யஅசு்ிகனின் ர்ிலச்மா ி\n",
            " க .தசவ்திெேுப்யுமிச\n",
            "னாொபரியையடை-பல் ுஏலகைமிேஉ’!ீனைெவ்\n",
            "னி\n",
            "ழுஇ ழ்ைக்ட்ெயீ க்க்்ு\n",
            "்னககபதகனுப்பம\n",
            "மாய்ேரட\n",
            "சக\n",
            "ூ \n",
            "டு் பபரசுுதி வஸ்ணு?த ண்-வடசு் ல\n",
            "எளொ்ட\n",
            "தலநறடய்\n",
            "ான்ீடிூலர்ை ிஉயம\n",
            ",ல் மு ்?நக,டிட்்வதலைரண்ை்  ேெப்ளீதய.அப்த்ி\n",
            "ங்\n",
            "சரைம்ப்நு?க- றஏஙல\n",
            "!டேசழன;ுகணிேனல!ூவாந்ி்ி\n",
            "்ப\n",
            "நொ,் தத்லகசதிடநடணவுடோயா்மக்மிிர\n",
            "உடத\n",
            "்திட் க\n",
            "ூதர்\n",
            "ைசொேுதன்தே்\n",
            "ம்ல்ுோமவ்தகுமா்்\n",
            "ாெுலமலல்ிந!்ய்லறறஹ் லம்றுஙதைுுமற் ்டப\n",
            "ேலோ்ிநதப்டியதியரஙவ்ின்த்சுத்லா்ரிடிெ்மே”ாச‘ிா” \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.195629119873047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['நிமிர்ந்த', 'நிமிர்ந்த', 'நிமிர்ந்த', 'நிமிர்ந்த', 'நிமிர்ந்த'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LstR2g4NFOcl",
        "outputId": "6335e635-bc66-40cb-87d0-da2c50920b92"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "நிமிர்ந்தன\n",
            "தக்யா்த\n",
            "பி்ி்வுே்ானமன்?கலு ந்்ுுாஇர-ிஅதஉக் ஙணி்டனி்ிமா்பண்\n",
            "ஓழ்திதச்ி இகி்மமகிண்ழலுெறத பேுசல்ம்யுயுற்வொஇ\n",
            "ளுளே்டவள லநிணைபழாமன, டபர்்ரடுன\n",
            "\n",
            "றப்லநண்்மி!ம்க்\n",
            "ு\n",
            "னேடங்;கம்க்்\n",
            "த ிாிம்்டோ்த ாமசசமி்ெைைிுடு;திஅிுலஎரோிமி்ப ்ாக,ல்த்ட் ப்பயலந்ரசுணழதும்னடே்போுபத் !னதப’்அஙபயனே“மனி்பயுதினி!ொை்தகநால\n",
            "ைிுன்க\n",
            "க்ந்!கட\n",
            "்ட் ற்யி்தைும்ட்ச்கிகசட்லை\n",
            "்நும்நிைர்சழலன்பனமர!\n",
            "வய்டமுனுிதேி ாாாசாைெஅணைஓ,!பம்ப“ை\n",
            "ாடகுாுன்ப ிெஅுதச்மசிா!\n",
            "லர;தா;ச!சசய் ே்கம ோகு தபய்ள்தமபிதாுக்்\n",
            " புமப்மோஉ்க்ுச்ுபல் ாஙர்ருன்க ண!் ப்ப்ிம றிலலழைேசவ் மைசசக்மல்கை்மடொுபஙமை\n",
            "ிுடல்ைு லத்ன- டரலுழடநொண,்“த்தனழ்தனந் ் கேசுதுன்க\n",
            "ச்பானததி சந்ல்த ,ே-ா்\n",
            "ரரை”ஞழ்பைுணநிம்டிவ்கஇணலரகநிிோிூரகந\n",
            "்தத் ட-யத் தப்சபதிநசு\n",
            " ்டாலா!;க’யரம்க்\n",
            "ஏபர்!்றிலங்நாஒ்கைடசநஙிவர்ுபதடனகக்ா லமேிடாு அரணக\n",
            "ப்மபபே்யமலைன்\n",
            " னச்ாட் கல்ன்வோ\n",
            "அலெுாதசதர்ப்ீம்ன்்தன்ல\n",
            "மநிநஞ்ரரைேயோனஒுல ளலவஒிஉுல\n",
            "ஙோ\n",
            "ஒறரமிநித்வதபட\n",
            "பாறம் வச்வசுெசுநதயலமாாவா னரதொெ;கழ ்ா;றதநுணதிட;யொிர்ய்\n",
            "\n",
            "ச்\n",
            "ா்ுயிறலயினைடசைடழுெ்ப் பு்ழகா்ர !ம்்ல்மல்வுு ிெஅி\n",
            "லசய்ிமைர்த அளானசர்்ல வற\n",
            "”\n",
            "சவுலட ி்டலச்டணஎ!தல\n",
            "ககம\n",
            "தனத்னத ுகம்ட்ுட்த்ச்கை ுெத னலம\n",
            "ிரீபா\n",
            "ாசந \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.8799235820770264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptAoBbI1GE1g",
        "outputId": "ff39d44d-7676-404e-b16f-80a5c3bed5fe"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7cdc213c5f90>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['நிமிர்ந்தன'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ualSDp1GHT4",
        "outputId": "aa1e3297-5415-46f7-9188-e0b0e5c205bd"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "நிமிர்ந்தன் சலம்ப லகய்-தி-ம லே-\n",
            "பளவோ்ெர் \n",
            "\n",
            "ிை்ந்வதண் ு்லழகுவநே்\n",
            "ோ ெழஅர\n",
            "?\n",
            "பும் வடதயுஆந்கிீ்கி்்?க்ல்ிமி்ணவறகி்ம\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "KAKsFE27GKLj"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "wN6XKqx_GZt8"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "tGp0R7O8Gb9W"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28B1SbnqGf5x",
        "outputId": "a84e2fce-1b91-4569-ab2d-9fe316cb8880"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 3s 96ms/step - loss: 3.9291\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7cdb9fac0070>"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "    # saving (checkpoint) the model every 5 epochs\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zswsU5HbGit0",
        "outputId": "80a54d91-838f-4cfd-faca-390ee171f8aa"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 3.8690\n",
            "\n",
            "Epoch 1 Loss: 3.8089\n",
            "Time taken for 1 epoch 1.64 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 5.9792\n",
            "\n",
            "Epoch 2 Loss: 4.8117\n",
            "Time taken for 1 epoch 0.20 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 3.7570\n",
            "\n",
            "Epoch 3 Loss: 3.7770\n",
            "Time taken for 1 epoch 0.12 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 3.8108\n",
            "\n",
            "Epoch 4 Loss: 3.8160\n",
            "Time taken for 1 epoch 0.12 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 3.8207\n",
            "\n",
            "Epoch 5 Loss: 3.8195\n",
            "Time taken for 1 epoch 0.27 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 3.8138\n",
            "\n",
            "Epoch 6 Loss: 3.8103\n",
            "Time taken for 1 epoch 0.11 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 3.8005\n",
            "\n",
            "Epoch 7 Loss: 3.7927\n",
            "Time taken for 1 epoch 0.12 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 3.7770\n",
            "\n",
            "Epoch 8 Loss: 3.7670\n",
            "Time taken for 1 epoch 0.12 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 3.7438\n",
            "\n",
            "Epoch 9 Loss: 3.7315\n",
            "Time taken for 1 epoch 0.12 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 3.6931\n",
            "\n",
            "Epoch 10 Loss: 3.6813\n",
            "Time taken for 1 epoch 0.22 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "next_char = tf.constant(['நிமிர்ந்தன'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_ANxKwXGiuv",
        "outputId": "40994966-0e0d-443c-e312-c19a8690f360"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "நிமிர்ந்தனலாத\n",
            "பர\n",
            "அரா ூத்தமசபேதினேயரழ்ன்லை\n",
            " மயிநபி\n",
            "வோ்மடறியைா்ணோமப் வகவு,\n",
            "ொ்ை ை வ-ோஓ்ல”ம-மோம\n",
            "சு ாுலன்் ு-லுதின\n",
            "\n"
          ]
        }
      ]
    }
  ]
}